{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a75d4b73",
   "metadata": {},
   "source": [
    "# Fake News Detection via Text Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f0c57f",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1cb86d07",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dskra\\AppData\\Local\\Temp\\ipykernel_20960\\1243621754.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk import pos_tag\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "import string\n",
    "from collections import Counter\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b301c1bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\dskra\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\dskra\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\dskra\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\dskra\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\dskra\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f96fbbb8",
   "metadata": {},
   "source": [
    "### Load the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d062b50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fake = pd.read_csv('fake.csv')\n",
    "df_true = pd.read_csv('true.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f57566eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fake['authenticity'] = 0\n",
    "df_true['authenticity'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b06322a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df_fake, df_true])\n",
    "df = df.sample(frac=1, random_state=42)\n",
    "\n",
    "df = df.sample(frac=1, random_state=42).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "92514ea0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "620db09561c349bfa6f7ee8e199cabe6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Text:   0%|          | 0/44898 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def preprocess_text(text):\n",
    "    # Lowercase\n",
    "    text = text.lower()\n",
    "    # Remove punctuation\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    # Tokenize\n",
    "    words = word_tokenize(text)\n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "    # Lemmatization\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    words = [lemmatizer.lemmatize(word) for word in words]\n",
    "    return words\n",
    "\n",
    "df_processed = df\n",
    "tqdm.pandas(desc=\"Processing Text\")\n",
    "df_processed['text_clean'] = df_processed['text'].progress_apply(preprocess_text)\n",
    "df_fake_processed = df_processed[df_processed['authenticity'] == 0]\n",
    "df_true_processed = df_processed[df_processed['authenticity'] == 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f92226",
   "metadata": {},
   "source": [
    "## 1) Explore Essential Information from Text Data and Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d38d54f3",
   "metadata": {},
   "source": [
    "##### 1. What are the most commonly used words (top 100) in the collection, the most commonly used words (top 100) in the real news and most commonly used words (top 100) in the fake news?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "54bd59d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = [word for sublist in df_processed['text_clean'] for word in sublist]\n",
    "fake_words = [word for sublist in df_fake_processed['text_clean'] for word in sublist]\n",
    "true_words = [word for sublist in df_true_processed['text_clean'] for word in sublist]\n",
    "\n",
    "word_counts_all = Counter(all_words).most_common(100)\n",
    "word_counts_fake = Counter(fake_words).most_common(100)\n",
    "word_counts_true = Counter(true_words).most_common(100)\n",
    "\n",
    "df_word_counts = pd.DataFrame({\n",
    "    'Rank': range(1, len(word_counts_all) + 1),\n",
    "    'word_counts_all': word_counts_all,\n",
    "    'word_counts_fake': word_counts_fake,\n",
    "    'word_counts_true': word_counts_true\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "faa29796",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>word_counts_all</th>\n",
       "      <th>word_counts_fake</th>\n",
       "      <th>word_counts_true</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>(said, 130050)</td>\n",
       "      <td>(trump, 73744)</td>\n",
       "      <td>(said, 99042)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>(trump, 128096)</td>\n",
       "      <td>(said, 31008)</td>\n",
       "      <td>(’, 70768)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>(’, 70768)</td>\n",
       "      <td>(president, 26073)</td>\n",
       "      <td>(trump, 54352)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>(u, 63450)</td>\n",
       "      <td>(people, 26031)</td>\n",
       "      <td>(“, 54140)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>(state, 58336)</td>\n",
       "      <td>(one, 23682)</td>\n",
       "      <td>(”, 53861)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>(would, 54945)</td>\n",
       "      <td>(would, 23420)</td>\n",
       "      <td>(u, 41166)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>(“, 54140)</td>\n",
       "      <td>(u, 22284)</td>\n",
       "      <td>(state, 36385)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>(”, 53861)</td>\n",
       "      <td>(state, 21951)</td>\n",
       "      <td>(would, 31525)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>(president, 53070)</td>\n",
       "      <td>(clinton, 18595)</td>\n",
       "      <td>(reuters, 28403)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>(people, 41354)</td>\n",
       "      <td>(like, 18139)</td>\n",
       "      <td>(president, 26997)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>(republican, 38106)</td>\n",
       "      <td>(obama, 17760)</td>\n",
       "      <td>(republican, 22109)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>(one, 36737)</td>\n",
       "      <td>(time, 17692)</td>\n",
       "      <td>(government, 19466)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>(year, 33507)</td>\n",
       "      <td>(donald, 17101)</td>\n",
       "      <td>(year, 18769)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>(also, 31174)</td>\n",
       "      <td>(american, 16013)</td>\n",
       "      <td>(house, 16934)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>(new, 30921)</td>\n",
       "      <td>(republican, 15997)</td>\n",
       "      <td>(new, 16786)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>(reuters, 28766)</td>\n",
       "      <td>(say, 15440)</td>\n",
       "      <td>(also, 15953)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>(government, 28519)</td>\n",
       "      <td>(also, 15221)</td>\n",
       "      <td>(united, 15574)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>(clinton, 28113)</td>\n",
       "      <td>(year, 14738)</td>\n",
       "      <td>(people, 15323)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>(house, 27646)</td>\n",
       "      <td>(new, 14135)</td>\n",
       "      <td>(party, 14990)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>(donald, 27554)</td>\n",
       "      <td>(news, 14099)</td>\n",
       "      <td>(official, 14580)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>(obama, 26955)</td>\n",
       "      <td>(image, 13831)</td>\n",
       "      <td>(told, 14244)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>(time, 26818)</td>\n",
       "      <td>(even, 13659)</td>\n",
       "      <td>(country, 14079)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>(say, 25385)</td>\n",
       "      <td>(hillary, 13532)</td>\n",
       "      <td>(election, 13959)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>(country, 24799)</td>\n",
       "      <td>(white, 13114)</td>\n",
       "      <td>(could, 13710)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>(could, 23899)</td>\n",
       "      <td>(right, 12489)</td>\n",
       "      <td>(one, 13055)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>(united, 23538)</td>\n",
       "      <td>(get, 12207)</td>\n",
       "      <td>(last, 12632)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>(told, 23344)</td>\n",
       "      <td>(know, 11918)</td>\n",
       "      <td>(washington, 12427)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>(election, 23172)</td>\n",
       "      <td>(make, 11522)</td>\n",
       "      <td>(two, 11624)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>(party, 22996)</td>\n",
       "      <td>(via, 11164)</td>\n",
       "      <td>(campaign, 11113)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>(american, 22878)</td>\n",
       "      <td>(woman, 11159)</td>\n",
       "      <td>(group, 11113)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>31</td>\n",
       "      <td>(like, 22777)</td>\n",
       "      <td>(campaign, 11068)</td>\n",
       "      <td>(former, 10601)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>32</td>\n",
       "      <td>(white, 22616)</td>\n",
       "      <td>(medium, 11057)</td>\n",
       "      <td>(leader, 10521)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>33</td>\n",
       "      <td>(campaign, 22181)</td>\n",
       "      <td>(country, 10720)</td>\n",
       "      <td>(week, 10485)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>34</td>\n",
       "      <td>(official, 20986)</td>\n",
       "      <td>(house, 10712)</td>\n",
       "      <td>(donald, 10453)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>35</td>\n",
       "      <td>(last, 20457)</td>\n",
       "      <td>(america, 10585)</td>\n",
       "      <td>(security, 10408)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>36</td>\n",
       "      <td>(right, 20389)</td>\n",
       "      <td>(could, 10189)</td>\n",
       "      <td>(court, 10357)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>37</td>\n",
       "      <td>(news, 20094)</td>\n",
       "      <td>(first, 9986)</td>\n",
       "      <td>(percent, 9948)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>38</td>\n",
       "      <td>(two, 19932)</td>\n",
       "      <td>(want, 9807)</td>\n",
       "      <td>(say, 9945)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>39</td>\n",
       "      <td>(group, 19042)</td>\n",
       "      <td>(going, 9745)</td>\n",
       "      <td>(north, 9872)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>40</td>\n",
       "      <td>(first, 18552)</td>\n",
       "      <td>(think, 9727)</td>\n",
       "      <td>(minister, 9542)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>41</td>\n",
       "      <td>(washington, 17901)</td>\n",
       "      <td>(many, 9690)</td>\n",
       "      <td>(clinton, 9518)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>42</td>\n",
       "      <td>(law, 17862)</td>\n",
       "      <td>(way, 9351)</td>\n",
       "      <td>(white, 9502)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>43</td>\n",
       "      <td>(make, 17678)</td>\n",
       "      <td>(election, 9213)</td>\n",
       "      <td>(law, 9297)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>44</td>\n",
       "      <td>(former, 17664)</td>\n",
       "      <td>(day, 9172)</td>\n",
       "      <td>(tax, 9245)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>45</td>\n",
       "      <td>(even, 17573)</td>\n",
       "      <td>(told, 9100)</td>\n",
       "      <td>(senate, 9221)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>46</td>\n",
       "      <td>(week, 16697)</td>\n",
       "      <td>(government, 9053)</td>\n",
       "      <td>(obama, 9195)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>47</td>\n",
       "      <td>(get, 16585)</td>\n",
       "      <td>(thing, 8915)</td>\n",
       "      <td>(time, 9126)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>48</td>\n",
       "      <td>(many, 16411)</td>\n",
       "      <td>(made, 8662)</td>\n",
       "      <td>(vote, 9010)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>49</td>\n",
       "      <td>(day, 16378)</td>\n",
       "      <td>(law, 8565)</td>\n",
       "      <td>(month, 8764)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>50</td>\n",
       "      <td>(hillary, 16273)</td>\n",
       "      <td>(video, 8564)</td>\n",
       "      <td>(china, 8593)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>51</td>\n",
       "      <td>(security, 16065)</td>\n",
       "      <td>(back, 8560)</td>\n",
       "      <td>(first, 8566)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>52</td>\n",
       "      <td>(vote, 16041)</td>\n",
       "      <td>(police, 8537)</td>\n",
       "      <td>(national, 8536)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>53</td>\n",
       "      <td>(court, 15857)</td>\n",
       "      <td>(go, 8395)</td>\n",
       "      <td>(statement, 8527)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>54</td>\n",
       "      <td>(national, 15728)</td>\n",
       "      <td>(two, 8308)</td>\n",
       "      <td>(administration, 8420)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>55</td>\n",
       "      <td>(want, 15579)</td>\n",
       "      <td>(black, 8019)</td>\n",
       "      <td>(since, 8332)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>56</td>\n",
       "      <td>(medium, 15505)</td>\n",
       "      <td>(party, 8006)</td>\n",
       "      <td>(tuesday, 8268)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>57</td>\n",
       "      <td>(may, 15438)</td>\n",
       "      <td>(show, 7977)</td>\n",
       "      <td>(democratic, 8240)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>58</td>\n",
       "      <td>(political, 15250)</td>\n",
       "      <td>(united, 7964)</td>\n",
       "      <td>(foreign, 8197)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>59</td>\n",
       "      <td>(made, 14875)</td>\n",
       "      <td>(group, 7929)</td>\n",
       "      <td>(including, 8119)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>60</td>\n",
       "      <td>(woman, 14858)</td>\n",
       "      <td>(last, 7825)</td>\n",
       "      <td>(military, 8052)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>61</td>\n",
       "      <td>(democrat, 14823)</td>\n",
       "      <td>(take, 7784)</td>\n",
       "      <td>(wednesday, 8012)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>62</td>\n",
       "      <td>(leader, 14756)</td>\n",
       "      <td>(come, 7749)</td>\n",
       "      <td>(presidential, 8012)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>63</td>\n",
       "      <td>(police, 14612)</td>\n",
       "      <td>(see, 7706)</td>\n",
       "      <td>(democrat, 7951)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>64</td>\n",
       "      <td>(million, 14451)</td>\n",
       "      <td>(may, 7626)</td>\n",
       "      <td>(right, 7900)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>65</td>\n",
       "      <td>(image, 14430)</td>\n",
       "      <td>(political, 7545)</td>\n",
       "      <td>(russia, 7853)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>66</td>\n",
       "      <td>(know, 14416)</td>\n",
       "      <td>(fact, 7340)</td>\n",
       "      <td>(may, 7812)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>67</td>\n",
       "      <td>(since, 14319)</td>\n",
       "      <td>(national, 7192)</td>\n",
       "      <td>(political, 7705)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>68</td>\n",
       "      <td>(percent, 14173)</td>\n",
       "      <td>(report, 7174)</td>\n",
       "      <td>(support, 7669)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>69</td>\n",
       "      <td>(bill, 14150)</td>\n",
       "      <td>(need, 7146)</td>\n",
       "      <td>(thursday, 7662)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>70</td>\n",
       "      <td>(going, 14106)</td>\n",
       "      <td>(well, 7079)</td>\n",
       "      <td>(bill, 7614)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>71</td>\n",
       "      <td>(support, 14061)</td>\n",
       "      <td>(former, 7063)</td>\n",
       "      <td>(million, 7559)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>72</td>\n",
       "      <td>(administration, 13984)</td>\n",
       "      <td>(vote, 7031)</td>\n",
       "      <td>(policy, 7523)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>73</td>\n",
       "      <td>(think, 13878)</td>\n",
       "      <td>(world, 6964)</td>\n",
       "      <td>(plan, 7404)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>74</td>\n",
       "      <td>(take, 13822)</td>\n",
       "      <td>(much, 6916)</td>\n",
       "      <td>(friday, 7332)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>75</td>\n",
       "      <td>(way, 13789)</td>\n",
       "      <td>(million, 6892)</td>\n",
       "      <td>(korea, 7267)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>76</td>\n",
       "      <td>(back, 13737)</td>\n",
       "      <td>(democrat, 6872)</td>\n",
       "      <td>(day, 7206)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>77</td>\n",
       "      <td>(presidential, 13703)</td>\n",
       "      <td>(life, 6700)</td>\n",
       "      <td>(monday, 7099)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>78</td>\n",
       "      <td>(month, 13340)</td>\n",
       "      <td>(story, 6650)</td>\n",
       "      <td>(force, 7077)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>79</td>\n",
       "      <td>(statement, 13303)</td>\n",
       "      <td>(bill, 6536)</td>\n",
       "      <td>(office, 6953)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>80</td>\n",
       "      <td>(america, 13132)</td>\n",
       "      <td>(public, 6509)</td>\n",
       "      <td>(committee, 6886)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>81</td>\n",
       "      <td>(russia, 13118)</td>\n",
       "      <td>(official, 6406)</td>\n",
       "      <td>(american, 6865)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>82</td>\n",
       "      <td>(member, 13104)</td>\n",
       "      <td>(support, 6392)</td>\n",
       "      <td>(member, 6844)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>83</td>\n",
       "      <td>(democratic, 13006)</td>\n",
       "      <td>(man, 6311)</td>\n",
       "      <td>(deal, 6838)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>84</td>\n",
       "      <td>(tax, 12915)</td>\n",
       "      <td>(attack, 6278)</td>\n",
       "      <td>(many, 6721)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>85</td>\n",
       "      <td>(senate, 12721)</td>\n",
       "      <td>(member, 6260)</td>\n",
       "      <td>(agency, 6538)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>86</td>\n",
       "      <td>(policy, 12694)</td>\n",
       "      <td>(week, 6212)</td>\n",
       "      <td>(congress, 6499)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>87</td>\n",
       "      <td>(including, 12613)</td>\n",
       "      <td>(according, 6205)</td>\n",
       "      <td>(senator, 6486)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>88</td>\n",
       "      <td>(office, 12519)</td>\n",
       "      <td>(never, 6180)</td>\n",
       "      <td>(federal, 6447)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>89</td>\n",
       "      <td>(north, 12437)</td>\n",
       "      <td>(another, 6171)</td>\n",
       "      <td>(department, 6360)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>90</td>\n",
       "      <td>(according, 12346)</td>\n",
       "      <td>(really, 6147)</td>\n",
       "      <td>(issue, 6336)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>91</td>\n",
       "      <td>(attack, 12296)</td>\n",
       "      <td>(family, 6138)</td>\n",
       "      <td>(city, 6323)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>92</td>\n",
       "      <td>(report, 12115)</td>\n",
       "      <td>(every, 6011)</td>\n",
       "      <td>(company, 6229)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>93</td>\n",
       "      <td>(need, 12034)</td>\n",
       "      <td>(since, 5987)</td>\n",
       "      <td>(made, 6213)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>94</td>\n",
       "      <td>(department, 11989)</td>\n",
       "      <td>(candidate, 5978)</td>\n",
       "      <td>(make, 6156)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>95</td>\n",
       "      <td>(public, 11881)</td>\n",
       "      <td>(work, 5873)</td>\n",
       "      <td>(part, 6143)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>96</td>\n",
       "      <td>(go, 11788)</td>\n",
       "      <td>(case, 5749)</td>\n",
       "      <td>(according, 6141)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>97</td>\n",
       "      <td>(federal, 11757)</td>\n",
       "      <td>(still, 5727)</td>\n",
       "      <td>(comment, 6133)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>98</td>\n",
       "      <td>(world, 11746)</td>\n",
       "      <td>(presidential, 5691)</td>\n",
       "      <td>(police, 6075)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>99</td>\n",
       "      <td>(come, 11683)</td>\n",
       "      <td>(child, 5689)</td>\n",
       "      <td>(called, 6047)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>100</td>\n",
       "      <td>(via, 11673)</td>\n",
       "      <td>(muslim, 5677)</td>\n",
       "      <td>(take, 6038)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Rank          word_counts_all      word_counts_fake  \\\n",
       "0      1           (said, 130050)        (trump, 73744)   \n",
       "1      2          (trump, 128096)         (said, 31008)   \n",
       "2      3               (’, 70768)    (president, 26073)   \n",
       "3      4               (u, 63450)       (people, 26031)   \n",
       "4      5           (state, 58336)          (one, 23682)   \n",
       "5      6           (would, 54945)        (would, 23420)   \n",
       "6      7               (“, 54140)            (u, 22284)   \n",
       "7      8               (”, 53861)        (state, 21951)   \n",
       "8      9       (president, 53070)      (clinton, 18595)   \n",
       "9     10          (people, 41354)         (like, 18139)   \n",
       "10    11      (republican, 38106)        (obama, 17760)   \n",
       "11    12             (one, 36737)         (time, 17692)   \n",
       "12    13            (year, 33507)       (donald, 17101)   \n",
       "13    14            (also, 31174)     (american, 16013)   \n",
       "14    15             (new, 30921)   (republican, 15997)   \n",
       "15    16         (reuters, 28766)          (say, 15440)   \n",
       "16    17      (government, 28519)         (also, 15221)   \n",
       "17    18         (clinton, 28113)         (year, 14738)   \n",
       "18    19           (house, 27646)          (new, 14135)   \n",
       "19    20          (donald, 27554)         (news, 14099)   \n",
       "20    21           (obama, 26955)        (image, 13831)   \n",
       "21    22            (time, 26818)         (even, 13659)   \n",
       "22    23             (say, 25385)      (hillary, 13532)   \n",
       "23    24         (country, 24799)        (white, 13114)   \n",
       "24    25           (could, 23899)        (right, 12489)   \n",
       "25    26          (united, 23538)          (get, 12207)   \n",
       "26    27            (told, 23344)         (know, 11918)   \n",
       "27    28        (election, 23172)         (make, 11522)   \n",
       "28    29           (party, 22996)          (via, 11164)   \n",
       "29    30        (american, 22878)        (woman, 11159)   \n",
       "30    31            (like, 22777)     (campaign, 11068)   \n",
       "31    32           (white, 22616)       (medium, 11057)   \n",
       "32    33        (campaign, 22181)      (country, 10720)   \n",
       "33    34        (official, 20986)        (house, 10712)   \n",
       "34    35            (last, 20457)      (america, 10585)   \n",
       "35    36           (right, 20389)        (could, 10189)   \n",
       "36    37            (news, 20094)         (first, 9986)   \n",
       "37    38             (two, 19932)          (want, 9807)   \n",
       "38    39           (group, 19042)         (going, 9745)   \n",
       "39    40           (first, 18552)         (think, 9727)   \n",
       "40    41      (washington, 17901)          (many, 9690)   \n",
       "41    42             (law, 17862)           (way, 9351)   \n",
       "42    43            (make, 17678)      (election, 9213)   \n",
       "43    44          (former, 17664)           (day, 9172)   \n",
       "44    45            (even, 17573)          (told, 9100)   \n",
       "45    46            (week, 16697)    (government, 9053)   \n",
       "46    47             (get, 16585)         (thing, 8915)   \n",
       "47    48            (many, 16411)          (made, 8662)   \n",
       "48    49             (day, 16378)           (law, 8565)   \n",
       "49    50         (hillary, 16273)         (video, 8564)   \n",
       "50    51        (security, 16065)          (back, 8560)   \n",
       "51    52            (vote, 16041)        (police, 8537)   \n",
       "52    53           (court, 15857)            (go, 8395)   \n",
       "53    54        (national, 15728)           (two, 8308)   \n",
       "54    55            (want, 15579)         (black, 8019)   \n",
       "55    56          (medium, 15505)         (party, 8006)   \n",
       "56    57             (may, 15438)          (show, 7977)   \n",
       "57    58       (political, 15250)        (united, 7964)   \n",
       "58    59            (made, 14875)         (group, 7929)   \n",
       "59    60           (woman, 14858)          (last, 7825)   \n",
       "60    61        (democrat, 14823)          (take, 7784)   \n",
       "61    62          (leader, 14756)          (come, 7749)   \n",
       "62    63          (police, 14612)           (see, 7706)   \n",
       "63    64         (million, 14451)           (may, 7626)   \n",
       "64    65           (image, 14430)     (political, 7545)   \n",
       "65    66            (know, 14416)          (fact, 7340)   \n",
       "66    67           (since, 14319)      (national, 7192)   \n",
       "67    68         (percent, 14173)        (report, 7174)   \n",
       "68    69            (bill, 14150)          (need, 7146)   \n",
       "69    70           (going, 14106)          (well, 7079)   \n",
       "70    71         (support, 14061)        (former, 7063)   \n",
       "71    72  (administration, 13984)          (vote, 7031)   \n",
       "72    73           (think, 13878)         (world, 6964)   \n",
       "73    74            (take, 13822)          (much, 6916)   \n",
       "74    75             (way, 13789)       (million, 6892)   \n",
       "75    76            (back, 13737)      (democrat, 6872)   \n",
       "76    77    (presidential, 13703)          (life, 6700)   \n",
       "77    78           (month, 13340)         (story, 6650)   \n",
       "78    79       (statement, 13303)          (bill, 6536)   \n",
       "79    80         (america, 13132)        (public, 6509)   \n",
       "80    81          (russia, 13118)      (official, 6406)   \n",
       "81    82          (member, 13104)       (support, 6392)   \n",
       "82    83      (democratic, 13006)           (man, 6311)   \n",
       "83    84             (tax, 12915)        (attack, 6278)   \n",
       "84    85          (senate, 12721)        (member, 6260)   \n",
       "85    86          (policy, 12694)          (week, 6212)   \n",
       "86    87       (including, 12613)     (according, 6205)   \n",
       "87    88          (office, 12519)         (never, 6180)   \n",
       "88    89           (north, 12437)       (another, 6171)   \n",
       "89    90       (according, 12346)        (really, 6147)   \n",
       "90    91          (attack, 12296)        (family, 6138)   \n",
       "91    92          (report, 12115)         (every, 6011)   \n",
       "92    93            (need, 12034)         (since, 5987)   \n",
       "93    94      (department, 11989)     (candidate, 5978)   \n",
       "94    95          (public, 11881)          (work, 5873)   \n",
       "95    96              (go, 11788)          (case, 5749)   \n",
       "96    97         (federal, 11757)         (still, 5727)   \n",
       "97    98           (world, 11746)  (presidential, 5691)   \n",
       "98    99            (come, 11683)         (child, 5689)   \n",
       "99   100             (via, 11673)        (muslim, 5677)   \n",
       "\n",
       "          word_counts_true  \n",
       "0            (said, 99042)  \n",
       "1               (’, 70768)  \n",
       "2           (trump, 54352)  \n",
       "3               (“, 54140)  \n",
       "4               (”, 53861)  \n",
       "5               (u, 41166)  \n",
       "6           (state, 36385)  \n",
       "7           (would, 31525)  \n",
       "8         (reuters, 28403)  \n",
       "9       (president, 26997)  \n",
       "10     (republican, 22109)  \n",
       "11     (government, 19466)  \n",
       "12           (year, 18769)  \n",
       "13          (house, 16934)  \n",
       "14            (new, 16786)  \n",
       "15           (also, 15953)  \n",
       "16         (united, 15574)  \n",
       "17         (people, 15323)  \n",
       "18          (party, 14990)  \n",
       "19       (official, 14580)  \n",
       "20           (told, 14244)  \n",
       "21        (country, 14079)  \n",
       "22       (election, 13959)  \n",
       "23          (could, 13710)  \n",
       "24            (one, 13055)  \n",
       "25           (last, 12632)  \n",
       "26     (washington, 12427)  \n",
       "27            (two, 11624)  \n",
       "28       (campaign, 11113)  \n",
       "29          (group, 11113)  \n",
       "30         (former, 10601)  \n",
       "31         (leader, 10521)  \n",
       "32           (week, 10485)  \n",
       "33         (donald, 10453)  \n",
       "34       (security, 10408)  \n",
       "35          (court, 10357)  \n",
       "36         (percent, 9948)  \n",
       "37             (say, 9945)  \n",
       "38           (north, 9872)  \n",
       "39        (minister, 9542)  \n",
       "40         (clinton, 9518)  \n",
       "41           (white, 9502)  \n",
       "42             (law, 9297)  \n",
       "43             (tax, 9245)  \n",
       "44          (senate, 9221)  \n",
       "45           (obama, 9195)  \n",
       "46            (time, 9126)  \n",
       "47            (vote, 9010)  \n",
       "48           (month, 8764)  \n",
       "49           (china, 8593)  \n",
       "50           (first, 8566)  \n",
       "51        (national, 8536)  \n",
       "52       (statement, 8527)  \n",
       "53  (administration, 8420)  \n",
       "54           (since, 8332)  \n",
       "55         (tuesday, 8268)  \n",
       "56      (democratic, 8240)  \n",
       "57         (foreign, 8197)  \n",
       "58       (including, 8119)  \n",
       "59        (military, 8052)  \n",
       "60       (wednesday, 8012)  \n",
       "61    (presidential, 8012)  \n",
       "62        (democrat, 7951)  \n",
       "63           (right, 7900)  \n",
       "64          (russia, 7853)  \n",
       "65             (may, 7812)  \n",
       "66       (political, 7705)  \n",
       "67         (support, 7669)  \n",
       "68        (thursday, 7662)  \n",
       "69            (bill, 7614)  \n",
       "70         (million, 7559)  \n",
       "71          (policy, 7523)  \n",
       "72            (plan, 7404)  \n",
       "73          (friday, 7332)  \n",
       "74           (korea, 7267)  \n",
       "75             (day, 7206)  \n",
       "76          (monday, 7099)  \n",
       "77           (force, 7077)  \n",
       "78          (office, 6953)  \n",
       "79       (committee, 6886)  \n",
       "80        (american, 6865)  \n",
       "81          (member, 6844)  \n",
       "82            (deal, 6838)  \n",
       "83            (many, 6721)  \n",
       "84          (agency, 6538)  \n",
       "85        (congress, 6499)  \n",
       "86         (senator, 6486)  \n",
       "87         (federal, 6447)  \n",
       "88      (department, 6360)  \n",
       "89           (issue, 6336)  \n",
       "90            (city, 6323)  \n",
       "91         (company, 6229)  \n",
       "92            (made, 6213)  \n",
       "93            (make, 6156)  \n",
       "94            (part, 6143)  \n",
       "95       (according, 6141)  \n",
       "96         (comment, 6133)  \n",
       "97          (police, 6075)  \n",
       "98          (called, 6047)  \n",
       "99            (take, 6038)  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_rows', 100)\n",
    "df_word_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8723d68c",
   "metadata": {},
   "source": [
    "##### 2. By reading the preprocessed textual data, can you easily tell the difference between the real news and fake news? What does the strongest feature set (for machine learning) look like?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58d06e62",
   "metadata": {},
   "source": [
    "By having many more instances of the word \"said\" in the true news data set, it is evident that real news samples show a much higher incidence of direct quotes, also evidenced by the high count of single and double quotation marks. Fake news data seems to also employ the use of emphasis/absolute words such as \"never\", \"even\", or \"really\" at a higher rate than the fake news data. Furthermore, these fake news texts also seem to use more words meant to incite a reaction such as \"attack\" or contain more demographic-based words such as \"black\" or \"muslim\". \n",
    "\n",
    "As for the strongest feature set, it might be useful to focus on POS tagging with noun, verb, and adjective/adverb filters to highlight these differences. A way to look into context usage of high-frequency words might also be helpful."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "530e5f75",
   "metadata": {},
   "source": [
    "# 2) Build Machine Learning Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a3a2796",
   "metadata": {},
   "source": [
    "## Test/Train Split Setup "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f610cecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df_processed['text'], df_processed['authenticity'], test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53eaaebb",
   "metadata": {},
   "source": [
    "## Feature Set TF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f844c2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectorizer = CountVectorizer()\n",
    "tf_train = count_vectorizer.fit_transform(X_train)\n",
    "tf_test = count_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f14b96f",
   "metadata": {},
   "source": [
    "## Feature Set TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "41e158ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.7)\n",
    "tfidf_train = tfidf_vectorizer.fit_transform(X_train)\n",
    "tfidf_test = tfidf_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79278ed9",
   "metadata": {},
   "source": [
    "## 2.1) Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1cad7da",
   "metadata": {},
   "source": [
    "### 2.1.1) Using TF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "25a8e5dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9952487008166295\n",
      "Confusion Matrix:\n",
      "[[6914   39]\n",
      " [  25 6492]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00      6953\n",
      "           1       0.99      1.00      1.00      6517\n",
      "\n",
      "    accuracy                           1.00     13470\n",
      "   macro avg       1.00      1.00      1.00     13470\n",
      "weighted avg       1.00      1.00      1.00     13470\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr_model = LogisticRegression(max_iter=1000)\n",
    "lr_model.fit(tf_train, y_train)\n",
    "\n",
    "predictions = lr_model.predict(tf_test)\n",
    "\n",
    "accuracy_tf_reg = accuracy_score(y_test, predictions)\n",
    "conf_matrix_tf_reg = confusion_matrix(y_test, predictions)\n",
    "report_tf_reg = classification_report(y_test, predictions)\n",
    "precision_tf_reg = precision_score(y_test, predictions, average='macro')\n",
    "recall_tf_reg = recall_score(y_test, predictions, average='macro')\n",
    "\n",
    "print(f'Accuracy: {accuracy_tf_reg}')\n",
    "print('Confusion Matrix:')\n",
    "print(conf_matrix_tf_reg)\n",
    "print('Classification Report:')\n",
    "print(report_tf_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af1995ca",
   "metadata": {},
   "source": [
    "### 2.1.2) Using TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5e116924",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9846325167037862\n",
      "Confusion Matrix:\n",
      "[[6838  115]\n",
      " [  92 6425]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99      6953\n",
      "           1       0.98      0.99      0.98      6517\n",
      "\n",
      "    accuracy                           0.98     13470\n",
      "   macro avg       0.98      0.98      0.98     13470\n",
      "weighted avg       0.98      0.98      0.98     13470\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr_model = LogisticRegression(max_iter=1000)\n",
    "lr_model.fit(tfidf_train, y_train)\n",
    "\n",
    "predictions = lr_model.predict(tfidf_test)\n",
    "\n",
    "accuracy_tfidf_reg = accuracy_score(y_test, predictions)\n",
    "conf_matrix_tfidf_reg = confusion_matrix(y_test, predictions)\n",
    "report_tfidf_reg = classification_report(y_test, predictions)\n",
    "precision_tfidf_reg = precision_score(y_test, predictions, average='macro')\n",
    "recall_tfidf_reg = recall_score(y_test, predictions, average='macro')\n",
    "\n",
    "print(f'Accuracy: {accuracy_tfidf_reg}')\n",
    "print('Confusion Matrix:')\n",
    "print(conf_matrix_tfidf_reg)\n",
    "print('Classification Report:')\n",
    "print(report_tfidf_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c10441",
   "metadata": {},
   "source": [
    "## 2.2) SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b17c57cc",
   "metadata": {},
   "source": [
    "### 2.2.1) Using TF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "701319db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9949517446176689\n",
      "Confusion Matrix:\n",
      "[[6911   42]\n",
      " [  26 6491]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00      6953\n",
      "           1       0.99      1.00      0.99      6517\n",
      "\n",
      "    accuracy                           0.99     13470\n",
      "   macro avg       0.99      0.99      0.99     13470\n",
      "weighted avg       0.99      0.99      0.99     13470\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svm_model = SVC(kernel='linear')\n",
    "svm_model.fit(tf_train, y_train)\n",
    "\n",
    "predictions = svm_model.predict(tf_test)\n",
    "\n",
    "accuracy_tf_svm = accuracy_score(y_test, predictions)\n",
    "conf_matrix_tf_svm = confusion_matrix(y_test, predictions)\n",
    "report_tf_svm = classification_report(y_test, predictions)\n",
    "precision_tf_svm = precision_score(y_test, predictions, average='macro')\n",
    "recall_tf_svm = recall_score(y_test, predictions, average='macro')\n",
    "\n",
    "print(f'Accuracy: {accuracy_tf_svm}')\n",
    "print('Confusion Matrix:')\n",
    "print(conf_matrix_tf_svm)\n",
    "print('Classification Report:')\n",
    "print(report_tf_svm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b351a631",
   "metadata": {},
   "source": [
    "### 2.2.2) Using TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "785312d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9933184855233853\n",
      "Confusion Matrix:\n",
      "[[6900   53]\n",
      " [  37 6480]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      6953\n",
      "           1       0.99      0.99      0.99      6517\n",
      "\n",
      "    accuracy                           0.99     13470\n",
      "   macro avg       0.99      0.99      0.99     13470\n",
      "weighted avg       0.99      0.99      0.99     13470\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svm_model = SVC(kernel='linear')\n",
    "svm_model.fit(tfidf_train, y_train)\n",
    "\n",
    "predictions = svm_model.predict(tfidf_test)\n",
    "\n",
    "accuracy_tfidf_svm = accuracy_score(y_test, predictions)\n",
    "conf_matrix_tfidf_svm = confusion_matrix(y_test, predictions)\n",
    "report_tfidf_svm = classification_report(y_test, predictions)\n",
    "precision_tfidf_svm = precision_score(y_test, predictions, average='macro')\n",
    "recall_tfidf_svm = recall_score(y_test, predictions, average='macro')\n",
    "\n",
    "print(f'Accuracy: {accuracy_tfidf_svm}')\n",
    "print('Confusion Matrix:')\n",
    "print(conf_matrix_tfidf_svm)\n",
    "print('Classification Report:')\n",
    "print(report_tfidf_svm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "158387af",
   "metadata": {},
   "source": [
    "## 2.3) Random Forest Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "817a68c7",
   "metadata": {},
   "source": [
    "### 2.3.1) Using TF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "965ce783",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9896807720861173\n",
      "Confusion Matrix:\n",
      "[[6879   74]\n",
      " [  65 6452]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      6953\n",
      "           1       0.99      0.99      0.99      6517\n",
      "\n",
      "    accuracy                           0.99     13470\n",
      "   macro avg       0.99      0.99      0.99     13470\n",
      "weighted avg       0.99      0.99      0.99     13470\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(tf_train, y_train)\n",
    "\n",
    "predictions = rf_model.predict(tf_test)\n",
    "\n",
    "accuracy_tf_rf = accuracy_score(y_test, predictions)\n",
    "conf_matrix_tf_rf = confusion_matrix(y_test, predictions)\n",
    "report_tf_rf = classification_report(y_test, predictions)\n",
    "precision_tf_rf = precision_score(y_test, predictions, average='macro')\n",
    "recall_tf_rf = recall_score(y_test, predictions, average='macro')\n",
    "\n",
    "print(f'Accuracy: {accuracy_tf_rf}')\n",
    "print('Confusion Matrix:')\n",
    "print(conf_matrix_tf_rf)\n",
    "print('Classification Report:')\n",
    "print(report_tf_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc050f7a",
   "metadata": {},
   "source": [
    "### 2.3.2) Using TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ea5036a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9844840386043059\n",
      "Confusion Matrix:\n",
      "[[6859   94]\n",
      " [ 115 6402]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98      6953\n",
      "           1       0.99      0.98      0.98      6517\n",
      "\n",
      "    accuracy                           0.98     13470\n",
      "   macro avg       0.98      0.98      0.98     13470\n",
      "weighted avg       0.98      0.98      0.98     13470\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(tfidf_train, y_train)\n",
    "\n",
    "predictions = rf_model.predict(tfidf_test)\n",
    "\n",
    "accuracy_tfidf_rf = accuracy_score(y_test, predictions)\n",
    "conf_matrix_tfidf_rf = confusion_matrix(y_test, predictions)\n",
    "report_tfidf_rf = classification_report(y_test, predictions)\n",
    "precision_tfidf_rf = precision_score(y_test, predictions, average='macro')\n",
    "recall_tfidf_rf = recall_score(y_test, predictions, average='macro')\n",
    "\n",
    "print(f'Accuracy: {accuracy_tfidf_rf}')\n",
    "print('Confusion Matrix:')\n",
    "print(conf_matrix_tfidf_rf)\n",
    "print('Classification Report:')\n",
    "print(report_tfidf_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ef357f",
   "metadata": {},
   "source": [
    "## 2.4) Gradient Boosting Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b8ab75c",
   "metadata": {},
   "source": [
    "### 2.4.1) Using TF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6be2ac7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9941351150705271\n",
      "Confusion Matrix:\n",
      "[[6892   61]\n",
      " [  18 6499]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99      6953\n",
      "           1       0.99      1.00      0.99      6517\n",
      "\n",
      "    accuracy                           0.99     13470\n",
      "   macro avg       0.99      0.99      0.99     13470\n",
      "weighted avg       0.99      0.99      0.99     13470\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gbm_model = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)\n",
    "gbm_model.fit(tf_train, y_train)\n",
    "\n",
    "predictions = gbm_model.predict(tf_test)\n",
    "\n",
    "accuracy_tf_gbm = accuracy_score(y_test, predictions)\n",
    "conf_matrix_tf_gbm = confusion_matrix(y_test, predictions)\n",
    "report_tf_gbm = classification_report(y_test, predictions)\n",
    "precision_tf_gbm = precision_score(y_test, predictions, average='macro')\n",
    "recall_tf_gbm = recall_score(y_test, predictions, average='macro')\n",
    "\n",
    "print(f'Accuracy: {accuracy_tf_gbm}')\n",
    "print('Confusion Matrix:')\n",
    "print(conf_matrix_tf_gbm)\n",
    "print('Classification Report:')\n",
    "print(report_tf_gbm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c24b0a04",
   "metadata": {},
   "source": [
    "### 2.4.2) Using TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "36fa9630",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9846325167037862\n",
      "Confusion Matrix:\n",
      "[[6838  115]\n",
      " [  92 6425]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99      6953\n",
      "           1       0.98      0.99      0.98      6517\n",
      "\n",
      "    accuracy                           0.98     13470\n",
      "   macro avg       0.98      0.98      0.98     13470\n",
      "weighted avg       0.98      0.98      0.98     13470\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gbm_model = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)\n",
    "gbm_model.fit(tfidf_train, y_train)\n",
    "\n",
    "predictions_tfidf_gbm = gbm_model.predict(tfidf_test)\n",
    "\n",
    "accuracy_tfidf_gbm = accuracy_score(y_test, predictions)\n",
    "conf_matrix_tfidf_gbm = confusion_matrix(y_test, predictions)\n",
    "report_tfidf_gbm = classification_report(y_test, predictions)\n",
    "precision_tfidf_gbm = precision_score(y_test, predictions, average='macro')\n",
    "recall_tfidf_gbm = recall_score(y_test, predictions, average='macro')\n",
    "\n",
    "print(f'Accuracy: {accuracy_tfidf_gbm}')\n",
    "print('Confusion Matrix:')\n",
    "print(conf_matrix_tfidf_gbm)\n",
    "print('Classification Report:')\n",
    "print(report_tfidf_gbm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28605a2e",
   "metadata": {},
   "source": [
    "## 2.5) MultinomialNB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66aeb13d",
   "metadata": {},
   "source": [
    "### 2.5.1) Using TF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "afd7a2c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9537490720118782\n",
      "Confusion Matrix:\n",
      "[[6620  333]\n",
      " [ 290 6227]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.95      0.96      6953\n",
      "           1       0.95      0.96      0.95      6517\n",
      "\n",
      "    accuracy                           0.95     13470\n",
      "   macro avg       0.95      0.95      0.95     13470\n",
      "weighted avg       0.95      0.95      0.95     13470\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nb_model = MultinomialNB()\n",
    "nb_model.fit(tf_train, y_train)\n",
    "\n",
    "predictions = nb_model.predict(tf_test)\n",
    "\n",
    "accuracy_tf_mnb = accuracy_score(y_test, predictions)\n",
    "conf_matrix_tf_mnb = confusion_matrix(y_test, predictions)\n",
    "report_tf_mnb = classification_report(y_test, predictions)\n",
    "precision_tf_mnb = precision_score(y_test, predictions, average='macro')\n",
    "recall_tf_mnb = recall_score(y_test, predictions, average='macro')\n",
    "\n",
    "print(f'Accuracy: {accuracy_tf_mnb}')\n",
    "print('Confusion Matrix:')\n",
    "print(conf_matrix_tf_mnb)\n",
    "print('Classification Report:')\n",
    "print(report_tf_mnb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4603dd8",
   "metadata": {},
   "source": [
    "### 2.5.2) Using TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ac3fe023",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9373422420193022\n",
      "Confusion Matrix:\n",
      "[[6611  342]\n",
      " [ 502 6015]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.95      0.94      6953\n",
      "           1       0.95      0.92      0.93      6517\n",
      "\n",
      "    accuracy                           0.94     13470\n",
      "   macro avg       0.94      0.94      0.94     13470\n",
      "weighted avg       0.94      0.94      0.94     13470\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nb_model = MultinomialNB()\n",
    "nb_model.fit(tfidf_train, y_train)\n",
    "\n",
    "predictions = nb_model.predict(tfidf_test)\n",
    "\n",
    "accuracy_tfidf_mnb = accuracy_score(y_test, predictions)\n",
    "conf_matrix_tfidf_mnb = confusion_matrix(y_test, predictions)\n",
    "report_tfidf_mnb = classification_report(y_test, predictions)\n",
    "precision_tfidf_mnb = precision_score(y_test, predictions, average='macro')\n",
    "recall_tfidf_mnb = recall_score(y_test, predictions, average='macro')\n",
    "\n",
    "print(f'Accuracy: {accuracy_tfidf_mnb}')\n",
    "print('Confusion Matrix:')\n",
    "print(conf_matrix_tfidf_mnb)\n",
    "print('Classification Report:')\n",
    "print(report_tfidf_mnb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c39ec15c",
   "metadata": {},
   "source": [
    "## 2.6) Performance Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "47f41ae6-65b5-4718-9951-0c2ca02f4e9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "| ML Model                       | Feature | Precision                    | Recall                      | Accuracy                    |\n",
       "|--------------------------------|---------|------------------------------|-----------------------------|-----------------------------|\n",
       "| Logistic Regression            | TF     | 0.9952              | 0.9953               | 0.9952               |\n",
       "| Logistic Regression            | TFIDF  | 0.9846              | 0.9847               | 0.9846               |\n",
       "| Support Vector Machine         | TF     | 0.9949              | 0.9950               | 0.9950               |\n",
       "| Support Vector Machine         | TFIDF  | 0.9933              | 0.9933               | 0.9933               |\n",
       "| Random Forest                  | TF     | 0.9897              | 0.9897               | 0.9897               |\n",
       "| Random Forest                  | TFIDF  | 0.9845              | 0.9844               | 0.9845               |\n",
       "| Gradient Boosting Machine      | TF     | 0.9940              | 0.9942               | 0.9941               |\n",
       "| Gradient Boosting Machine      | TFIDF  | 0.9846              | 0.9847               | 0.9846               |\n",
       "| Multinomial Naive Bayes        | TF     | 0.9536              | 0.9538               | 0.9537               |\n",
       "| Multinomial Naive Bayes        | TFIDF  | 0.9378              | 0.9369               | 0.9373               |\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "header = \"| ML Model                       | Feature | Precision                    | Recall                      | Accuracy                    |\"\n",
    "separator = \"|--------------------------------|---------|------------------------------|-----------------------------|-----------------------------|\"\n",
    "row_template = \"| {model:<30} | {feature:<6} | {precision:.4f}              | {recall:.4f}               | {accuracy:.4f}               |\"\n",
    "\n",
    "markdown_table = f\"{header}\\n{separator}\\n\"\n",
    "\n",
    "model_accuracies = []\n",
    "\n",
    "models_features = [\n",
    "    (\"Logistic Regression\", \"reg\", \"tf\"),\n",
    "    (\"Logistic Regression\", \"reg\", \"tfidf\"),\n",
    "    (\"Support Vector Machine\", \"svm\", \"tf\"),\n",
    "    (\"Support Vector Machine\", \"svm\", \"tfidf\"),\n",
    "    (\"Random Forest\", \"rf\", \"tf\"),\n",
    "    (\"Random Forest\", \"rf\", \"tfidf\"),\n",
    "    (\"Gradient Boosting Machine\", \"gbm\", \"tf\"),\n",
    "    (\"Gradient Boosting Machine\", \"gbm\", \"tfidf\"),\n",
    "    (\"Multinomial Naive Bayes\", \"mnb\", \"tf\"),\n",
    "    (\"Multinomial Naive Bayes\", \"mnb\", \"tfidf\"),\n",
    "]\n",
    "\n",
    "for model, model_short, feature in models_features:\n",
    "    precision_var_name = f\"precision_{feature}_{model_short}\"\n",
    "    recall_var_name = f\"recall_{feature}_{model_short}\"\n",
    "    accuracy_var_name = f\"accuracy_{feature}_{model_short}\"\n",
    "    conf_matrix_var_name = f\"conf_matrix_{feature}_{model_short}\"\n",
    "\n",
    "    try:\n",
    "        precision = float(locals().get(precision_var_name, 0))\n",
    "        recall = float(locals().get(recall_var_name, 0))\n",
    "        accuracy = float(locals().get(accuracy_var_name, 0))\n",
    "        conf_matrix = locals().get(conf_matrix_var_name, \"N/A\")\n",
    "    except ValueError:\n",
    "        precision = recall = accuracy = \"N/A\"\n",
    "        conf_matrix = \"N/A\"\n",
    "\n",
    "    if accuracy != \"N/A\":\n",
    "        model_accuracies.append((accuracy, model, model_short, feature, conf_matrix))\n",
    "    \n",
    "    markdown_table += row_template.format(model=model, feature=feature.upper(), precision=precision, recall=recall, accuracy=accuracy) + \"\\n\"\n",
    "\n",
    "display(Markdown(markdown_table))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ba1d57ab-85e9-41fb-9861-e44538053d6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "## 2.7) Top 2 Models based on Accuracy\n",
       "\n",
       "### Logistic Regression (TF)\n",
       "Confusion Matrix:\n",
       "\n",
       "|               | Predicted Positive | Predicted Negative |\n",
       "|---------------|--------------------|--------------------|\n",
       "| Actual Positive | 6914 (TP)    | 39 (FP)    |\n",
       "| Actual Negative | 25 (FN)    | 6492 (TN)    |\n",
       "\n",
       "### Support Vector Machine (TF)\n",
       "Confusion Matrix:\n",
       "\n",
       "|               | Predicted Positive | Predicted Negative |\n",
       "|---------------|--------------------|--------------------|\n",
       "| Actual Positive | 6911 (TP)    | 42 (FP)    |\n",
       "| Actual Negative | 26 (FN)    | 6491 (TN)    |\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "top_2_models = sorted(model_accuracies, key=lambda x: x[0], reverse=True)[:2]\n",
    "\n",
    "top_models_md = \"\\n## 2.7) Top 2 Models based on Accuracy\\n\"\n",
    "for _, model, model_short, feature, conf_matrix in top_2_models:\n",
    "    top_models_md += f\"\\n### {model} ({feature.upper()})\\n\"\n",
    "    top_models_md += \"Confusion Matrix:\\n\"\n",
    "    \n",
    "    conf_matrix_table = f\"\"\"\n",
    "|               | Predicted Positive | Predicted Negative |\n",
    "|---------------|--------------------|--------------------|\n",
    "| Actual Positive | {conf_matrix[0][0]} (TP)    | {conf_matrix[0][1]} (FP)    |\n",
    "| Actual Negative | {conf_matrix[1][0]} (FN)    | {conf_matrix[1][1]} (TN)    |\n",
    "\"\"\"\n",
    "    \n",
    "    top_models_md += conf_matrix_table\n",
    "\n",
    "display(Markdown(top_models_md))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efa6bca8",
   "metadata": {},
   "source": [
    "# 3) Enhanced NLP Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e8b90279",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_filtered = {}\n",
    "\n",
    "def filter_pos(sentences, filter_type, data_type):\n",
    "    filter_key = filter_type+', ' + data_type\n",
    "    \n",
    "    if filter_key in all_filtered:\n",
    "        return all_filtered[filter_key]\n",
    "    \n",
    "    filtered_sentences = []\n",
    "    for sentence in tqdm(sentences, desc=f'Filtering {filter_type}'):\n",
    "        tokenized = word_tokenize(sentence.lower())\n",
    "        tagged = pos_tag(tokenized)\n",
    "        \n",
    "        filters = {\n",
    "            'noun+adj': ['NN', 'JJ'],\n",
    "            'noun+verb': ['NN', 'VB'],\n",
    "            'noun+adj+verb': ['NN', 'JJ', 'VB']\n",
    "        }\n",
    "        \n",
    "        if filter_type in filters:\n",
    "            filtered = [word for word, tag in tagged if any(tag.startswith(t) for t in filters[filter_type])]\n",
    "        else:\n",
    "            filtered = tokenized\n",
    "        \n",
    "        filtered_sentences.append(\" \".join(filtered))\n",
    "        \n",
    "    all_filtered[filter_key] = filtered_sentences    \n",
    "    \n",
    "    return filtered_sentences\n",
    "\n",
    "def vectorize_data(data, filter_type, vectorizer_type, data_type, vectorizer=None):\n",
    "    filtered_texts = filter_pos(data, filter_type, data_type)\n",
    "    \n",
    "    if vectorizer is None:\n",
    "        if vectorizer_type == 'tf':\n",
    "            vectorizer = CountVectorizer()\n",
    "        elif vectorizer_type == 'tfidf':\n",
    "            vectorizer = TfidfVectorizer()\n",
    "        vectorized_data = vectorizer.fit_transform(filtered_texts)\n",
    "    else:\n",
    "        vectorized_data = vectorizer.transform(filtered_texts)\n",
    "    \n",
    "    return vectorized_data, vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c9d148-2e80-4617-a25b-d46598bbdfa3",
   "metadata": {},
   "source": [
    "## 3.1) Test 1: Noun + Adjective, TFIDF, Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a3b229b7-fbaa-46b1-b029-ea28d293ecdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c0b42c6a9ef400eabc44513398fe2cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filtering noun+adj:   0%|          | 0/31428 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eebee28186a94489a165daf48cae5902",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filtering noun+adj:   0%|          | 0/13470 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.987305122494432\n",
      "Confusion Matrix:\n",
      "[[6863   90]\n",
      " [  81 6436]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      6953\n",
      "           1       0.99      0.99      0.99      6517\n",
      "\n",
      "    accuracy                           0.99     13470\n",
      "   macro avg       0.99      0.99      0.99     13470\n",
      "weighted avg       0.99      0.99      0.99     13470\n",
      "\n"
     ]
    }
   ],
   "source": [
    "filter_type = 'noun+adj'  \n",
    "vectorizer_type = 'tfidf' \n",
    "\n",
    "X_train_vec, fitted_vectorizer = vectorize_data(X_train, filter_type, vectorizer_type, \"train\")\n",
    "X_test_vec, _ = vectorize_data(X_test, filter_type, vectorizer_type, \"test\", fitted_vectorizer)\n",
    "\n",
    "lr_model = LogisticRegression(max_iter=1000)\n",
    "lr_model.fit(X_train_vec, y_train)\n",
    "\n",
    "predictions = lr_model.predict(X_test_vec)\n",
    "\n",
    "accuracy_na_tfidf_reg = accuracy_score(y_test, predictions)\n",
    "conf_matrix_na_tfidf_reg = confusion_matrix(y_test, predictions)\n",
    "report_na_tfidf_reg = classification_report(y_test, predictions)\n",
    "precision_na_tfidf_reg = precision_score(y_test, predictions, average='macro')\n",
    "recall_na_tfidf_reg = recall_score(y_test, predictions, average='macro')\n",
    "\n",
    "print(f'Accuracy: {accuracy_na_tfidf_reg}')\n",
    "print('Confusion Matrix:')\n",
    "print(conf_matrix_na_tfidf_reg)\n",
    "print('Classification Report:')\n",
    "print(report_na_tfidf_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2cd6ae3-af9b-4618-9cc4-44732a2e8993",
   "metadata": {},
   "source": [
    "## 3.2) Test 2: Noun + Adjective, TF, SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2fea3f22-9e50-406c-ada9-acea8f7fe093",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9947290274684484\n",
      "Confusion Matrix:\n",
      "[[6911   42]\n",
      " [  29 6488]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99      6953\n",
      "           1       0.99      1.00      0.99      6517\n",
      "\n",
      "    accuracy                           0.99     13470\n",
      "   macro avg       0.99      0.99      0.99     13470\n",
      "weighted avg       0.99      0.99      0.99     13470\n",
      "\n"
     ]
    }
   ],
   "source": [
    "filter_type = 'noun+adj'  \n",
    "vectorizer_type = 'tf' \n",
    "\n",
    "X_train_vec, fitted_vectorizer = vectorize_data(X_train, filter_type, vectorizer_type, \"train\")\n",
    "X_test_vec, _ = vectorize_data(X_test, filter_type, vectorizer_type, \"test\", fitted_vectorizer)\n",
    "\n",
    "svm_model = SVC(kernel='linear')\n",
    "svm_model.fit(X_train_vec, y_train)\n",
    "\n",
    "predictions = svm_model.predict(X_test_vec)\n",
    "\n",
    "accuracy_na_tf_svm = accuracy_score(y_test, predictions)\n",
    "conf_matrix_na_tf_svm = confusion_matrix(y_test, predictions)\n",
    "report_na_tf_svm = classification_report(y_test, predictions)\n",
    "precision_na_tf_svm = precision_score(y_test, predictions, average='macro')\n",
    "recall_na_tf_svm = recall_score(y_test, predictions, average='macro')\n",
    "\n",
    "print(f'Accuracy: {accuracy_na_tf_svm}')\n",
    "print('Confusion Matrix:')\n",
    "print(conf_matrix_na_tf_svm)\n",
    "print('Classification Report:')\n",
    "print(report_na_tf_svm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a1c37d-a9bd-4553-ad05-9acb2b65dce3",
   "metadata": {},
   "source": [
    "## 3.3) Test 3: Noun + Adjective + Verb, TF, GBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "12587a72-256d-4154-bf35-8e8058bd911d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6dc5dcb5fe5c419c8f74cf042b7f6ed5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filtering noun+adj+verb:   0%|          | 0/31428 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7de88f5b0404172856ed2177d117115",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filtering noun+adj+verb:   0%|          | 0/13470 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.995025983667409\n",
      "Confusion Matrix:\n",
      "[[6907   46]\n",
      " [  21 6496]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00      6953\n",
      "           1       0.99      1.00      0.99      6517\n",
      "\n",
      "    accuracy                           1.00     13470\n",
      "   macro avg       0.99      1.00      1.00     13470\n",
      "weighted avg       1.00      1.00      1.00     13470\n",
      "\n"
     ]
    }
   ],
   "source": [
    "filter_type = 'noun+adj+verb'  \n",
    "vectorizer_type = 'tf' \n",
    "\n",
    "X_train_vec, fitted_vectorizer = vectorize_data(X_train, filter_type, vectorizer_type, \"train\")\n",
    "X_test_vec, _ = vectorize_data(X_test, filter_type, vectorizer_type, \"test\", fitted_vectorizer)\n",
    "\n",
    "gbm_model = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)\n",
    "gbm_model.fit(X_train_vec, y_train)\n",
    "\n",
    "predictions = gbm_model.predict(X_test_vec)\n",
    "\n",
    "accuracy_nav_tf_gbm = accuracy_score(y_test, predictions)\n",
    "conf_matrix_nav_tf_gbm = confusion_matrix(y_test, predictions)\n",
    "report_nav_tf_gbm = classification_report(y_test, predictions)\n",
    "precision_nav_tf_gbm = precision_score(y_test, predictions, average='macro')\n",
    "recall_nav_tf_gbm = recall_score(y_test, predictions, average='macro')\n",
    "\n",
    "print(f'Accuracy: {accuracy_nav_tf_gbm}')\n",
    "print('Confusion Matrix:')\n",
    "print(conf_matrix_nav_tf_gbm)\n",
    "print('Classification Report:')\n",
    "print(report_nav_tf_gbm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "587f1672-18a7-4e02-bb92-6c9f14a6c8aa",
   "metadata": {},
   "source": [
    "## 3.4) Test 4: Noun + Adjective, TFIDF, GBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fec40569-832a-4aa9-ace2-056d2c4e6e91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9947290274684484\n",
      "Confusion Matrix:\n",
      "[[6906   47]\n",
      " [  24 6493]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99      6953\n",
      "           1       0.99      1.00      0.99      6517\n",
      "\n",
      "    accuracy                           0.99     13470\n",
      "   macro avg       0.99      0.99      0.99     13470\n",
      "weighted avg       0.99      0.99      0.99     13470\n",
      "\n"
     ]
    }
   ],
   "source": [
    "filter_type = 'noun+adj'  \n",
    "vectorizer_type = 'tfidf' \n",
    "\n",
    "X_train_vec, fitted_vectorizer = vectorize_data(X_train, filter_type, vectorizer_type, \"train\")\n",
    "X_test_vec, _ = vectorize_data(X_test, filter_type, vectorizer_type, \"test\", fitted_vectorizer)\n",
    "\n",
    "gbm_model = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)\n",
    "gbm_model.fit(X_train_vec, y_train)\n",
    "\n",
    "predictions = gbm_model.predict(X_test_vec)\n",
    "\n",
    "accuracy_na_tfidf_gbm = accuracy_score(y_test, predictions)\n",
    "conf_matrix_na_tfidf_gbm = confusion_matrix(y_test, predictions)\n",
    "report_na_tfidf_gbm = classification_report(y_test, predictions)\n",
    "precision_na_tfidf_gbm = precision_score(y_test, predictions, average='macro')\n",
    "recall_na_tfidf_gbm = recall_score(y_test, predictions, average='macro')\n",
    "\n",
    "print(f'Accuracy: {accuracy_na_tfidf_gbm}')\n",
    "print('Confusion Matrix:')\n",
    "print(conf_matrix_na_tfidf_gbm)\n",
    "print('Classification Report:')\n",
    "print(report_na_tfidf_gbm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0dbe89f-8e67-4c04-84e2-b4d57bf42a9a",
   "metadata": {},
   "source": [
    "## 3.5) Test 5: Noun + Verb, TFIDF, SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4c3e0de2-bdea-45be-b917-c54f7aaad168",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eed17ab433d9473b8234aed679c31966",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filtering noun+verb:   0%|          | 0/31428 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60f9cd805c1a43cf9542eb6045dbb2a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filtering noun+verb:   0%|          | 0/13470 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9939866369710467\n",
      "Confusion Matrix:\n",
      "[[6905   48]\n",
      " [  33 6484]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99      6953\n",
      "           1       0.99      0.99      0.99      6517\n",
      "\n",
      "    accuracy                           0.99     13470\n",
      "   macro avg       0.99      0.99      0.99     13470\n",
      "weighted avg       0.99      0.99      0.99     13470\n",
      "\n"
     ]
    }
   ],
   "source": [
    "filter_type = 'noun+verb'  \n",
    "vectorizer_type = 'tfidf' \n",
    "\n",
    "X_train_vec, fitted_vectorizer = vectorize_data(X_train, filter_type, vectorizer_type, \"train\")\n",
    "X_test_vec, _ = vectorize_data(X_test, filter_type, vectorizer_type, \"test\", fitted_vectorizer)\n",
    "\n",
    "svm_model = SVC(kernel='linear')\n",
    "svm_model.fit(X_train_vec, y_train)\n",
    "\n",
    "predictions = svm_model.predict(X_test_vec)\n",
    "\n",
    "accuracy_nv_tfidf_svm = accuracy_score(y_test, predictions)\n",
    "conf_matrix_nv_tfidf_svm = confusion_matrix(y_test, predictions)\n",
    "report_nv_tfidf_svm = classification_report(y_test, predictions)\n",
    "precision_nv_tfidf_svm = precision_score(y_test, predictions, average='macro')\n",
    "recall_nv_tfidf_svm = recall_score(y_test, predictions, average='macro')\n",
    "\n",
    "print(f'Accuracy: {accuracy_nv_tfidf_svm}')\n",
    "print('Confusion Matrix:')\n",
    "print(conf_matrix_nv_tfidf_svm)\n",
    "print('Classification Report:')\n",
    "print(report_nv_tfidf_svm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb815bbf-eb18-440a-a14f-c34906eeb838",
   "metadata": {},
   "source": [
    "## 3.6) Test 6: Noun + Adjective + Verb, TF, Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bf740552-ae9b-4537-9ed0-70830d198a07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9920564216778025\n",
      "Confusion Matrix:\n",
      "[[6901   52]\n",
      " [  55 6462]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      6953\n",
      "           1       0.99      0.99      0.99      6517\n",
      "\n",
      "    accuracy                           0.99     13470\n",
      "   macro avg       0.99      0.99      0.99     13470\n",
      "weighted avg       0.99      0.99      0.99     13470\n",
      "\n"
     ]
    }
   ],
   "source": [
    "filter_type = 'noun+adj+verb'  \n",
    "vectorizer_type = 'tf' \n",
    "\n",
    "X_train_vec, fitted_vectorizer = vectorize_data(X_train, filter_type, vectorizer_type, \"train\")\n",
    "X_test_vec, _ = vectorize_data(X_test, filter_type, vectorizer_type, \"test\", fitted_vectorizer)\n",
    "\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train_vec, y_train)\n",
    "\n",
    "predictions = rf_model.predict(X_test_vec)\n",
    "\n",
    "accuracy_nav_tf_rf = accuracy_score(y_test, predictions)\n",
    "conf_matrix_nav_tf_rf = confusion_matrix(y_test, predictions)\n",
    "report_nav_tf_rf = classification_report(y_test, predictions)\n",
    "precision_nav_tf_rf = precision_score(y_test, predictions, average='macro')\n",
    "recall_nav_tf_rf = recall_score(y_test, predictions, average='macro')\n",
    "\n",
    "print(f'Accuracy: {accuracy_nav_tf_rf}')\n",
    "print('Confusion Matrix:')\n",
    "print(conf_matrix_nav_tf_rf)\n",
    "print('Classification Report:')\n",
    "print(report_nav_tf_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73e51490-cef8-4ad4-b91b-103a340a10c5",
   "metadata": {},
   "source": [
    "## 3.7) Test 7: Noun + Adjective, TFIDF, Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0d3e2502-bbde-4123-aa7d-f559109b5a66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9920564216778025\n",
      "Confusion Matrix:\n",
      "[[6900   53]\n",
      " [  54 6463]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      6953\n",
      "           1       0.99      0.99      0.99      6517\n",
      "\n",
      "    accuracy                           0.99     13470\n",
      "   macro avg       0.99      0.99      0.99     13470\n",
      "weighted avg       0.99      0.99      0.99     13470\n",
      "\n"
     ]
    }
   ],
   "source": [
    "filter_type = 'noun+adj'  \n",
    "vectorizer_type = 'tfidf' \n",
    "\n",
    "X_train_vec, fitted_vectorizer = vectorize_data(X_train, filter_type, vectorizer_type, \"train\")\n",
    "X_test_vec, _ = vectorize_data(X_test, filter_type, vectorizer_type, \"test\", fitted_vectorizer)\n",
    "\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train_vec, y_train)\n",
    "\n",
    "predictions = rf_model.predict(X_test_vec)\n",
    "\n",
    "accuracy_na_tfidf_rf = accuracy_score(y_test, predictions)\n",
    "conf_matrix_na_tfidf_rf = confusion_matrix(y_test, predictions)\n",
    "report_na_tfidf_rf = classification_report(y_test, predictions)\n",
    "precision_na_tfidf_rf = precision_score(y_test, predictions, average='macro')\n",
    "recall_na_tfidf_rf = recall_score(y_test, predictions, average='macro')\n",
    "\n",
    "print(f'Accuracy: {accuracy_na_tfidf_rf}')\n",
    "print('Confusion Matrix:')\n",
    "print(conf_matrix_na_tfidf_rf)\n",
    "print('Classification Report:')\n",
    "print(report_na_tfidf_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea3255f4-1173-4054-a579-8c93452066c6",
   "metadata": {},
   "source": [
    "## 3.8) Test 8: Noun + Verb, TFIDF, MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8bb2df73-fe7a-4516-a9d5-e19ff5ac0447",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9404602821083891\n",
      "Confusion Matrix:\n",
      "[[6626  327]\n",
      " [ 475 6042]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.95      0.94      6953\n",
      "           1       0.95      0.93      0.94      6517\n",
      "\n",
      "    accuracy                           0.94     13470\n",
      "   macro avg       0.94      0.94      0.94     13470\n",
      "weighted avg       0.94      0.94      0.94     13470\n",
      "\n"
     ]
    }
   ],
   "source": [
    "filter_type = 'noun+verb'  \n",
    "vectorizer_type = 'tfidf' \n",
    "\n",
    "X_train_vec, fitted_vectorizer = vectorize_data(X_train, filter_type, vectorizer_type, \"train\")\n",
    "X_test_vec, _ = vectorize_data(X_test, filter_type, vectorizer_type, \"test\", fitted_vectorizer)\n",
    "\n",
    "nb_model = MultinomialNB()\n",
    "nb_model.fit(X_train_vec, y_train)\n",
    "\n",
    "predictions = nb_model.predict(X_test_vec)\n",
    "\n",
    "accuracy_nv_tfidf_mnb = accuracy_score(y_test, predictions)\n",
    "conf_matrix_nv_tfidf_mnb = confusion_matrix(y_test, predictions)\n",
    "report_nv_tfidf_mnb = classification_report(y_test, predictions)\n",
    "precision_nv_tfidf_mnb = precision_score(y_test, predictions, average='macro')\n",
    "recall_nv_tfidf_mnb = recall_score(y_test, predictions, average='macro')\n",
    "\n",
    "print(f'Accuracy: {accuracy_nv_tfidf_mnb}')\n",
    "print('Confusion Matrix:')\n",
    "print(conf_matrix_nv_tfidf_mnb)\n",
    "print('Classification Report:')\n",
    "print(report_nv_tfidf_mnb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d9752b-099d-412c-baf8-15ec676a6d67",
   "metadata": {},
   "source": [
    "## 3.9) Test 9: Noun + Adjective + Verb, TF, Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "04b34848-13ee-474e-9a92-a80b638d4cfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9948775055679288\n",
      "Confusion Matrix:\n",
      "[[6919   34]\n",
      " [  35 6482]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00      6953\n",
      "           1       0.99      0.99      0.99      6517\n",
      "\n",
      "    accuracy                           0.99     13470\n",
      "   macro avg       0.99      0.99      0.99     13470\n",
      "weighted avg       0.99      0.99      0.99     13470\n",
      "\n"
     ]
    }
   ],
   "source": [
    "filter_type = 'noun+adj+verb'  \n",
    "vectorizer_type = 'tf' \n",
    "\n",
    "X_train_vec, fitted_vectorizer = vectorize_data(X_train, filter_type, vectorizer_type, \"train\")\n",
    "X_test_vec, _ = vectorize_data(X_test, filter_type, vectorizer_type, \"test\", fitted_vectorizer)\n",
    "\n",
    "lr_model = LogisticRegression(max_iter=1000)\n",
    "lr_model.fit(X_train_vec, y_train)\n",
    "\n",
    "predictions = lr_model.predict(X_test_vec)\n",
    "\n",
    "accuracy_nav_tf_reg = accuracy_score(y_test, predictions)\n",
    "conf_matrix_nav_tf_reg = confusion_matrix(y_test, predictions)\n",
    "report_nav_tf_reg = classification_report(y_test, predictions)\n",
    "precision_nav_tf_reg = precision_score(y_test, predictions, average='macro')\n",
    "recall_nav_tf_reg = recall_score(y_test, predictions, average='macro')\n",
    "\n",
    "print(f'Accuracy: {accuracy_nav_tf_reg}')\n",
    "print('Confusion Matrix:')\n",
    "print(conf_matrix_nav_tf_reg)\n",
    "print('Classification Report:')\n",
    "print(report_nav_tf_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9796a858-72c3-432d-8f12-12633750a38e",
   "metadata": {},
   "source": [
    "## 3.10) Test 10: Noun + Adjective, TFIDF, MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a1e0faa8-2f71-4e30-a3e2-5cee84c5c7d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9354862657757981\n",
      "Confusion Matrix:\n",
      "[[6591  362]\n",
      " [ 507 6010]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.95      0.94      6953\n",
      "           1       0.94      0.92      0.93      6517\n",
      "\n",
      "    accuracy                           0.94     13470\n",
      "   macro avg       0.94      0.94      0.94     13470\n",
      "weighted avg       0.94      0.94      0.94     13470\n",
      "\n"
     ]
    }
   ],
   "source": [
    "filter_type = 'noun+adj'  \n",
    "vectorizer_type = 'tfidf' \n",
    "\n",
    "X_train_vec, fitted_vectorizer = vectorize_data(X_train, filter_type, vectorizer_type, \"train\")\n",
    "X_test_vec, _ = vectorize_data(X_test, filter_type, vectorizer_type, \"test\", fitted_vectorizer)\n",
    "\n",
    "nb_model = MultinomialNB()\n",
    "nb_model.fit(X_train_vec, y_train)\n",
    "\n",
    "predictions = nb_model.predict(X_test_vec)\n",
    "\n",
    "accuracy_na_tfidf_mnb = accuracy_score(y_test, predictions)\n",
    "conf_matrix_na_tfidf_mnb = confusion_matrix(y_test, predictions)\n",
    "report_na_tfidf_mnb = classification_report(y_test, predictions)\n",
    "precision_na_tfidf_mnb = precision_score(y_test, predictions, average='macro')\n",
    "recall_na_tfidf_mnb = recall_score(y_test, predictions, average='macro')\n",
    "\n",
    "print(f'Accuracy: {accuracy_na_tfidf_mnb}')\n",
    "print('Confusion Matrix:')\n",
    "print(conf_matrix_na_tfidf_mnb)\n",
    "print('Classification Report:')\n",
    "print(report_na_tfidf_mnb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c323f1dd-e7c5-4d26-a14f-507e3facb270",
   "metadata": {},
   "source": [
    "## 3.11) Performance Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d9003f98-765b-4a64-b14e-18a6027dc271",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "| ML Model                       | Feature | Filter                     | Precision  | Recall    | Accuracy  |\n",
       "|--------------------------------|---------|----------------------------|------------|-----------|-----------|\n",
       "| Logistic Regression            | TFIDF  | Noun + Adjective            | 0.9873              | 0.9873               | 0.9873               |\n",
       "| Support Vector Machine         | TF     | Noun + Adjective            | 0.9947              | 0.9948               | 0.9947               |\n",
       "| Gradient Boosting Machine      | TF     | Noun + Adjective + Verb     | 0.9950              | 0.9951               | 0.9950               |\n",
       "| Gradient Boosting Machine      | TFIDF  | Noun + Adjective            | 0.9947              | 0.9948               | 0.9947               |\n",
       "| Support Vector Machine         | TFIDF  | Noun + Verb                 | 0.9939              | 0.9940               | 0.9940               |\n",
       "| Random Forest                  | TF     | Noun + Adjective + Verb     | 0.9921              | 0.9920               | 0.9921               |\n",
       "| Random Forest                  | TFIDF  | Noun + Adjective            | 0.9921              | 0.9920               | 0.9921               |\n",
       "| Multinomial Naive Bayes        | TFIDF  | Noun + Verb                 | 0.9409              | 0.9400               | 0.9405               |\n",
       "| Logistic Regression            | TF     | Noun + Adjective + Verb     | 0.9949              | 0.9949               | 0.9949               |\n",
       "| Multinomial Naive Bayes        | TFIDF  | Noun + Adjective            | 0.9359              | 0.9351               | 0.9355               |\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "header = \"| ML Model                       | Feature | Filter                     | Precision  | Recall    | Accuracy  |\"\n",
    "separator = \"|--------------------------------|---------|----------------------------|------------|-----------|-----------|\"\n",
    "\n",
    "row_template = \"| {model:<30} | {feature:<6} | {filter:<27} | {precision:.4f}              | {recall:.4f}               | {accuracy:.4f}               |\"\n",
    "\n",
    "markdown_table = f\"{header}\\n{separator}\\n\"\n",
    "\n",
    "models_features = [\n",
    "    (\"Logistic Regression\", \"na\", \"Noun + Adjective\", \"reg\", \"tfidf\"),\n",
    "    (\"Support Vector Machine\", \"na\", \"Noun + Adjective\", \"svm\", \"tf\"),\n",
    "    (\"Gradient Boosting Machine\", \"nav\", \"Noun + Adjective + Verb\", \"gbm\", \"tf\"),\n",
    "    (\"Gradient Boosting Machine\", \"na\", \"Noun + Adjective\", \"gbm\", \"tfidf\"),\n",
    "    (\"Support Vector Machine\", \"nv\", \"Noun + Verb\", \"svm\", \"tfidf\"),\n",
    "    (\"Random Forest\", \"nav\", \"Noun + Adjective + Verb\", \"rf\", \"tf\"),\n",
    "    (\"Random Forest\", \"na\", \"Noun + Adjective\", \"rf\", \"tfidf\"),\n",
    "    (\"Multinomial Naive Bayes\", \"nv\", \"Noun + Verb\", \"mnb\", \"tfidf\"),\n",
    "    (\"Logistic Regression\", \"nav\", \"Noun + Adjective + Verb\", \"reg\", \"tf\"),\n",
    "    (\"Multinomial Naive Bayes\", \"na\", \"Noun + Adjective\", \"mnb\", \"tfidf\"),\n",
    "]\n",
    "\n",
    "for model, filter_short, filter, model_short, feature in models_features:\n",
    "    precision_var_name = f\"precision_{filter_short}_{feature}_{model_short}\"\n",
    "    recall_var_name = f\"recall_{filter_short}_{feature}_{model_short}\"\n",
    "    accuracy_var_name = f\"accuracy_{filter_short}_{feature}_{model_short}\"\n",
    "    precision = locals().get(precision_var_name, \"N/A\")\n",
    "    recall = locals().get(recall_var_name, \"N/A\")\n",
    "    accuracy = locals().get(accuracy_var_name, \"N/A\")\n",
    "    \n",
    "    markdown_table += row_template.format(model=model, feature=feature.upper(), filter=filter, precision=precision, recall=recall, accuracy=accuracy) + \"\\n\"\n",
    "\n",
    "display(Markdown(markdown_table))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
